{
 "cells": [
  {
   "source": [
    "# Geodatenanalyse 1\n",
    "\n",
    "## Tag 2 / Block 2 / Übung 5: Multivariate Statistik"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In dieser Übung wollen wir uns mit der Analyse und Visualisierung von mehrdimensionalen Daten befassen. Lest dazu zunächst den vollständigeb Datensatz mit den Grundwasserparametern aus Karlsruhe in Python ein. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# [1] hier Code eingeben\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Data_GW_KA.csv', sep=';', encoding='cp1252')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### In 5 Schritten zur Hauptkomponentenanalyse\n",
    "\n",
    "#### 1. Standardisierung\n",
    "\n",
    "Da wir in der letzten Übung gesehen haben, dass die Varianzen und Kovarianzen der Parameter in dem Datensatz sehr unterschiedlich sind, sollten die Daten aller Parameter vor der weiteren Analyse an die Standard-Normalvereilung angepasst werden. Dazu gibt es in dem Python Package `sklearn` die Funktion `sklearn.preprocessing.StandardScaler().fit_transform()`. Die erste Klammer bleibt dabei leer, fügt den Namen Eures Datensatzes in der zweiten Klammer ein. \n",
    "\n",
    "Inspiziert anschließend den standardisierten Datensatz und überprüft ob die Daten wie gewünscht vorwiegend zwischen -1 und +1 liegen. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] hier Code eingeben"
   ]
  },
  {
   "source": [
    "#### 2. Eigenwerte und Eigenvektoren bestimmen\n",
    "\n",
    "Berechnet für die Bestimmung der Eigenwerte zuerst die Kovarianzmatrix mit Hilfe von `numpy` und der Funktion `numpy.cov(data.T)`. Wichtig ist hier das `.T` hinter dem Datensatz, das die transponierte Matrix von dem Datensatz bildet, das vereinfacht die weitere Handhabung der Matrizen. Anschließend könnt Ihr mit der Funktion `numpy.linalg.eig()` die Eigenwerte und Eigenvektoren der Kovarianzmatrix berechnen (2 Outputs definieren). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] hier Code eingeben"
   ]
  },
  {
   "source": [
    "#### 3. Hauptkomponenten bestimmen\n",
    "\n",
    "Das Ziel der Hauptkomponentenanalyse ist es die Dimensionen des Datensatzes zu reduzieren, z.B. auf zwei für eine 2D-Visualisierung. Die Richtung dieser Achsen im Parameterraum entspricht den Eigenvektoren (mit Einheitslänge 1). Damit möglichst viel Information in Form der Varianz, in den zwei Dimensionen erhalten bleibt, suchen wir nun jene Eigenvektoren mit den größter Eigenwerten. \n",
    "\n",
    "Definiert dafür einen Parameter vom Typ list ohne Inhalt als \"[[]]*n\", mit \"n\" als Dimension entsprechend der Anzahl der Eigenwerte. Dann füllt diese Liste über eine for Schleife mit den Absolutwerten der jeweiligen Eigenwerten und den Eigenvektoren (spaltenweise, also über einen einfachen Index, z.B. \"eigen[i]\").\n",
    "\n",
    "Schlussendlich sortiert diese Liste noch in absteigender Reihenfolge: `data.sort()` gibt Euch die aufsteigende Reihenfolge, `data.reverse()` davon die umgekehrte Reihenfolge. Die zwei obersten Einträge entsprechen dann den gesuchten Hauptkomponenten entlang den größten Varianzen. \n",
    "\n",
    "Speichert diese zwei obersten Einträge in separaten Variablen vom Typ `list` ab, und lasst Euch diese anzeigen. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] hier Code eingeben"
   ]
  },
  {
   "source": [
    "#### 4. Projektionsmatrix konstruieren\n",
    "\n",
    "Mit Hilfe der Projektionsmatrix wollen wir die ursprünglichen Daten auf die zwei neuen Achsen der Hauptkomponenten transformieren. Um die 15 Parameter auf 2 Dimensionen zu reduzieren brauchen wir also eine (15 x 2) Matrix, deren Spalten den beiden Eigenvektoren mit den größten Eigenwerten entsprechen. \n",
    "\n",
    "Die Eigenvektoren habt Ihr bereits im letzten Schritt (zusammen mit den Eigenwerten) als `list` und nach Größe sortiert gespeichtert. Fügt die beiden obersten Vektoren nun mit Hilfe von `numpy.stack((Vektor1, Vektor2))` und dem Argument `axis=-1` für eine horiziontale Ausrichtung zu einer Matrix `W` zusammen. \n",
    "\n",
    "Als Erinnerung: Die Indizierung funktioniert hier mit dem Syntax `\"list[Zeile][Spalte]\"`. Schaut nochmal in dem Ausgabefenster oben nach, welche Zelle der Variablen Ihr benötigt.  \n",
    "\n",
    "Lasst Euch anschließend \"W\" anzeigen.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] hier Code eingeben"
   ]
  },
  {
   "source": [
    "#### 5. Projektion auf neue Ebenen und Visualisierung\n",
    "\n",
    "Jetzt könnt Ihr über die Gleichung `Y = data x W ` die Transformation durchführen. Matrixmultiplikation in Python kann mit `matrix1.dot(matrix2)` durchgeführt werden. Die Output-Matrix Y sollte dann 39 x 2 (Datenpunkte x Hauptkomponenten) Dimensionen haben.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6] hier Code eingeben\n"
   ]
  },
  {
   "source": [
    "Diese finale, transformierte Matrix können wir nun mit Hilfe von `pandas` in einem DataFrame umwandeln, das erleicntert das weitere Arbeiten damit. Gleichzeitig ergänzen wir in dem DataFrame eine Spalte mit dem Parameter \"Flaechennutzung\". \n",
    "\n",
    "Ergänzt nun in dem Skript unten mit Hilfe von `matplotlib` einen Scatterplot der Daten mit den beiden Hauptkomponenten als Achsen, und der Flaechennutzung als Farbe der Punkte. Was lässt sich anhand dieser Abbildung über die Parameterwerte in Bezug auf die Flaechennutzung sagen?   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [7] aus ndarray einen DataFrame mit zwei Spalten erzeugen \n",
    "principalDf = pd.DataFrame(data = Y , columns = ['principal component 1', 'principal component 2'])\n",
    "# eine dritte Spalte mit den Werten der Flächennutzung ergänzen\n",
    "finalDf = pd.concat([principalDf,pd.DataFrame(data,columns = ['Flaechennutzung'])], axis = 1) \n",
    "\n",
    "# hier Abbildung erzeugen\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Hauptkomponentenanalyse mit sklearn\n",
    "\n",
    "Das Python Package `sklearn` enthält viele nützliche Funtkionen für statistische Analysen und maschinelles Lernen. Darunter auch eine Funktion für Hauptkomponentenanalyse `sklearn.decomposition.PCA()`. Definiert dafür zuerst ein Objekt das die genaue Methode beschreibt (z.B. als \"model\") mit Hilfe der Funktion `sklearn.decomposition.PCA()`. Definiert als Input wie viele Hauptkomponenten (\"n_components=2\") Ihr ausgegeben haben möchtet. \n",
    "\n",
    "Dann könnt Ihr den reduzierten Datensatz berechnen, indem Ihr auf diese Methode das Attribut `.fit_transform()` anwendet, mit dem ursprünglichen Datensatz als Input. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [8] hier Code eingeben"
   ]
  },
  {
   "source": [
    "Für die Bewertung der Aussagekraft einer Hauptkomponentenanalyse ist es wichtig zu wissen, wie viel der ursprünglich Varianz (und damit der Informationen) in dem neuen transformierten Datensatz enthalten ist. Für die einzelnen Komponenten könnt Ihr das ausrechnen, indem Ihr das Attribut `.explained_variance_ratio_` auf Euer PCA Objekt anwendet. Berechnet außerdem die Summe der Varianzen. \n",
    "\n",
    "Wie würdet Ihr die Werte einordnen und die Aussagekraft bewerten?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [9] hier Code eingeben"
   ]
  },
  {
   "source": [
    "Nun stellt auch die Ergebnisse der PCA mit `sklearn` analog zu oben graphisch dar, und vergleicht die beiden Ergebnisse."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [10] hier Code eingeben\n",
    "principalDf2 = pd.DataFrame(data = data_reduced, columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf2 = pd.concat([principalDf2,pd.DataFrame(data,columns = ['Flaechennutzung'])], axis = 1) \n",
    "\n",
    "# hier Abbildung erzeugen"
   ]
  },
  {
   "source": [
    "Wenn Ihr alles richtig gemacht habt, sollten die beiden Abbildung das gleiche Bild zeigen (u.U. gespiegelt oder rotiert, also mit einem Vorzeichenwechsel auf einer oder beiden Achsen). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## Ende\n",
    "\n",
    "### Referenzen: \n",
    "\n",
    "Koch et al. (2020), Groundwater fauna in an urban area: natural or affected? https://hess.copernicus.org/preprints/hess-2020-151/hess-2020-151.pdf\n",
    "\n",
    "Lever et al. (2017) Principal component analysis, Nature Methods 14(7), 641-642\n",
    "\n",
    "https://towardsdatascience.com/a-complete-guide-to-principal-component-analysis-pca-in-machine-learning-664f34fc3e5a\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}