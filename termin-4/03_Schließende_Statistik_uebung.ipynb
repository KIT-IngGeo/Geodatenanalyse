{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geodatenanalyse 1\n",
    "\n",
    "## Übung 3: Schließende Statistik - Übung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Übung wollen wir uns die Grundwasserdaten aus den letzten beiden Übungen genauer anschauen, und von den gemessenenen Stichproben auf die Gesamtgrundheit der Werte im Hardtwald schließen. Dazu lesen wir zuerst den kompletten Datensatz aus Excel in Python ein, und unterteilen ihn wie in der letzten Übung in die Daten aus dem Bereich des Waldes und der Stadt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] \n",
    "import numpy as np\n",
    "data = np.genfromtxt(open(\"Data_GW_KA.csv\", \"rb\"), delimiter=\";\", skip_header=1)\n",
    "data_urban = data[0:30]\n",
    "data_forest = data[31:39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der letzten Übung habt Ihr herausgefunden, dass man die Verteilung der gemessenenen Grundwassertemperaturen in der Stadt als normalverteilt annehmen kann. Angenommen Ihr wollt anschließend eine Modellierung durchführen und benötigt 50 zufällig verteilte Werte, die die gleiche statistische Verteilung aufweisen wie die gemessenen Grundwassertemperaturen. \n",
    "\n",
    "Dazu müsst Ihr zuerst herausfinden, welche Normalverteilung am besten auf Eure Daten passt. Also welchen Mittelwert und welche Varianz diese theoretische Verteilung hat. Benutzt dafür die Funktion `scipy.stats.norm.fit()`, die zwei Outputs ($\\mu$, $\\sigma$<sup>2</sup>) hat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] hier Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Funktion `scipy.stats.norm.rvs()` könnt Ihr nun beliebig viele Zufallswerte generieren. Als Inputs müsst Ihr dafür die zwei statistischen Momente der Normalverteilung angeben, sowie die gewünschte Zahl an Werten (50). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] hier Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiziert nun die erzeugten Werte. Lasst Euch zur Kontrolle auch Mittelwert und Varianz der erzeugten Werte anzeigen, und vergleicht diese mit den Werten der angepassten theoretischen Normalverteilung. Stimmen diese überein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] hier Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wahrscheinlich stimmen die Mittelwerte und Varianzen nicht genau überein. Das könnte an der recht geringen Anzahl an generierten Werten (50) liegen. Versucht es daher mal mit 500.000 Werten, und überprüft die statistischen Parameter erneut. Frei nach dem Prinzip \"Viel hilft viel\". \n",
    "\n",
    "Hinweis: Habt Geduld, die Ausführung mit n=500000 könnte etwas dauern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] hier Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mittelwert und Varianz sollten nun näher an den angepassten Werten von oben liegen. Allerdings führt die große Anzahl an Werten (neben längeren Rechenzeiten) bei vielen Verteilungen zu einem anderen Problem. Bestimmt für den eben erzeugten Datensatz den Minimal- und Maximalwert. Was fällt dabei auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6] hier Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basierend auf den gemessenen Daten erscheinen diese Werte viel zu niedrig, bzw. zu hoch. Das liegt daran, dass mit einer hohen Anzahl an Zufallswerten auch Werte in den Extrembereichen mit sehr geringen Wahrscheinlichkeiten generiert werden. \n",
    "\n",
    "Das lässt sich vermeiden, indem man mit gestutzten (engl. truncated) Verteilungen arbeitet. Die Funktion `scipy.stats.truncnorm.rvs()` generiert solche Verteilungen. Dafür müssen vor den statistischen Momenten zwei Skalierungsparameter (*a*, *b*) angegeben werden: \n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?a&space;=&space;(Minimalwert&space;-&space;mean)/&space;std\" title=\"a = (Minimalwert - mean)/ std\" />\n",
    "\n",
    "und \n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?b&space;=&space;(Maximalwert&space;-&space;mean)/&space;std\" title=\"b = (Maximalwert - mean)/ std\" />\n",
    "\n",
    "Überlegt Euch nun sinnvolle Minimal- und Maximalwerte für Eure theoretische Verteilung, berechnet *a* und *b*, und erzeugt damit eine gestutzte Verteilung für die Grundwassertemperaturen. Schaut euch dann die deskriptiven Merkmale der erzeugten Werte an.\n",
    "\n",
    "Hinweis: Als Funktionn für die Quadratwurzel könnt ihr `math.sqrt()` benutzen. Mit `scipy.stats.describe()` könnt Ihr Euch mit einem Befehl alle wichtigen statistitschen Parameter für eine Variable anzeigen lassen ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [7] hier Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Werte erfüllen unsere Bedinungen nun deutlich besser, und wir könnten sie für weitere Berechnungen nutzen. \n",
    "\n",
    "Natürlich gibt es auch Funktionen zum Anpassen an andere theoretische Verteilungen neben der Normalverteilung. Eine Übersicht über die in `scipy` verfügbaren Verteilungen findet Ihr hier: https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "\n",
    "Schlussendlich wird da Ganze natürlich viel anschaulicher, wenn man die beiden Verteilungen graphisch darstellt. Dafür findet Ihr im nächsten Fenster ein fertiges Skript. Führt es aus und schaut Euch die Verteilungen an. Wie beurteilt Ihr die optische Übereinstimmung? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [8] \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate x-values over range of GWT at which to calculate the probability \n",
    "x=numpy.linspace(data_urban[:,2].min(),data_urban[:,2].max(),1000)\n",
    "\n",
    "# calculate values of fitted probability function at x \n",
    "pdf=norm.pdf(x,mean_f,var_f)\n",
    "\n",
    "plt.plot(x,pdf,'r-') # plot fitted probability distribution\n",
    "plt.hist(data_urban[:,2], density =True, alpha=.3) # plot original data as histogram \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie genau man einen Code mit matplotlib für solche und weitere Abbildungen schreibt erfahrt Ihr morgen. \n",
    "\n",
    "\n",
    "## Ende"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
