{
 "cells": [
  {
   "source": [
    "# Geodatenanalyse 1\n",
    "\n",
    "## Tag 5 / Block 2 / Übung 13: Lineare Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In dieser Übung werden wir zwei Beispiele zur linearen Regression in Python durchführen. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Einfache Lineare Regression \"from scratch\" \n",
    "\n",
    "Für dieses Beispiel werden wir sythetische Daten benutzen. Diese haben den Vorteil, dass man die Ergebnisse der Analyse direkt mit den Parametern der erzeugten Daten überprüfen, und so die Methode und den Code validieren kann. \n",
    "\n",
    "Erzeugt euch nun synthetische Daten für eine einfache lineare Regressionsanalyse: \n",
    "\n",
    "- generiert 100 normalverteilte Zufallswerte für eine unabhängige Variable mit einem Mittelwert von 1.5 und einer Standardabweichung von 2.5 (z.B. mit Hilfe von `np.random.randn()`).\n",
    "\n",
    "- generiert ebenfalls 100 normalverteilte zufällige Residuen (mu = 0, std = 0.5).\n",
    "\n",
    "- erzeugt schließlich mit Hilfe der unabhängigen Variablen die abhängige Variable über eine lineare Funktion mit einem beliebigen Achsenabschnitt und einer beliebigen Steigung, und addiert die Residuen dazu.\n",
    "\n",
    "- Erezugt einen DataFrame aus den beiden Arrays.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Benutzt dann die Methode der Keinste-Quadrate-Schätzung, um diejenigen Regressionskoeffizienten (alpha, beta) zu berechnen, die die beste Übereinstimmung einer linearen Funktion und den erzeugten Daten liefern. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Vergleicht diese berechneten Regressionskoeffizienten mit den im ersten Schritt von euch festgelegten Werten der linearen Funktion. Wenn Ihr alles richtig gemacht habt, sollten diese recht gut übereinstimmen. \n",
    "\n",
    "Für die Visualisierung der Regressionsanalyse wollen wir nun die synthetischen Daten (Scatterplot) und die Regressionsfunktion (Linie) gemeinsam darstellen. \n",
    "Vorhersagen für die Regressionsfunktion könnt Ihr an den Werten der unabhängigen Variablen erzeugen, in dem Ihr diese in die lineare Funktion mit den ermittelten Regressionskoeffizienten einsetzt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "### 2. Multiple Lineare Regression mit scikit-learn\n",
    "\n",
    "Für diese Übung werden wir einen der Demo-Datensätze aus scikit-learn benutzten. Die \"Boston Housing Data\" enthält Daten zu 506 Häusern in Boston in Form von 13 Parametern: \n",
    "\n",
    "<img src=\"Boston_Data.png\" alt=\"boston\" width=\"500\"/>\n",
    "\n",
    "\n",
    "Wir wollen versuchen den Wert eines Hauses (\"MEDV\") in Abhängigkeit mehrerer anderer Parameter vorhersagen. \n",
    "\n",
    "Importiert dazu aus den scikit-learn Beispieldaten (`sklearn.datasets`) die Funktion `load_boston()`, und ladet damit den Datensatz ein. Wandelt anschließend die eigentlichen Daten (boston_dataset.data) in einen pandas DataFrame um, mit den \"feature_names\" als Spalten. Erstellt für diesen DataFrame eine weiteren Spalte \"MEDV\" basierend auf \"boston_dataset.target\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Verschafft Euch nun einen Überblick über die Daten (explorativen Datenanalyse). Erstellt dafür eine Korrelationsmatrix mit den abhängigen und unabhängigen Variablen, und visualisiert diese (s. Übung Bivariate Statistik). \n",
    "\n",
    "Wenn Ihr für Eure Heatmap `seaborn` benutzt, könnt Ihr mit dem Befehl \"sns.set(rc={'figure.figsize':(15,10)})\" die Abbildungsgröße anpassen, sodass alle Wert zu lesen sind. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben\n"
   ]
  },
  {
   "source": [
    "Wählt nun für die multiple lineare Regression der abhängigen Variablen zwei geeignete unabhängige Variablen aus: \n",
    "\n",
    "- diese sollten möglichst stark (> 0.7) mit der abhängigen Variablen \"MEDV\" korrelieren  \n",
    "\n",
    "- aber weniger stark miteinander korrelieren (< 0.7)\n",
    "\n",
    "Speichert diese zwei Variablen dann in einen separaten DataFrame ab."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Nun werden wir diesen Datensatz zur späteren Validierung in einen Trainings- und Test-Teil aufteilen. Die Funktion `sklearn.model_selection.train_test_split()` benötigt als Inputs die unabhängigen, sowie abhängigen Variablen und eine Angabe für die Größe des Test-Teils (\"test_size=0.2\").\n",
    "\n",
    "So werden zufallsbasiert 20% der Daten in dem Test-Datensatz abgespeichert, die übrigen 80% in dem Trainingsdatensatz. Entsprechend müssen für die Funktion vier Outputs definiert werden (z.B. als X_train, X_test, Y_train, Y_test)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Führt nun mit dem Trainingsdatensatz und der Funktion `sklearn.linear_model.LinearRegression()` eine lineare Regression durch. \n",
    "\n",
    "Wie die letzten Übungen auch, muss dafür zuerst ein Linear-Regression-Objekt erzeugt werden (mit den default Einstellungen). Passt dann über \".fit\" das Regressions-Objekt an die beiden Traniningsdatensätze (X und Y) an. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Nun wollen wir das angepasste multiple lineare Modell mit Hilfe geeigneter Fehlermaße und den Testdaten validieren. Importiert dafür aus `sklearn.metrics` den `mean_squared_error` und das Bestimmtheitsmaß `r2_score`. \n",
    "\n",
    "Wertet das Linear-Regression-Objekt über `.predict()` für die Werte der beiden abhängigen Variablen (jeweils von dem Trainings- und Testdatensatz) aus um Vorhersagewerte für die unabhängige Variable für beide Fälle zu erhalten. \n",
    "\n",
    "Um die Anpassung des Regressionsmodells an sich zu bewerten, bestimmt den RMSE zwischen den beobachteten und vorhergesagten Werten der abhängigen Variable an den Werten der unabhängigen Variable im Trainingsdatensatz. \n",
    "\n",
    "Um das Regressionsmodells außerhalb dieser Punkte zu validieren, verfahrt ebenso mit dem Testdatensatz. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Beurteilt nun zum Einen die Anpassung des linearen Modells an sich, als auch die Evaluation mit den Testdaten. Seid Ihr mit dem Ergebnis der Regression zufrieden?\n",
    "\n",
    "Wenn Ihr noch Zeit habt, könnt Ihr die Daten und Ergebisse und der multiplen linearen Regression noch visualisierenm, z.B. um die Daten optisch auf Ausreisser, Linearität usw. überprüfen. \n",
    "\n",
    "## Ende\n",
    "\n",
    "### Referenzen: \n",
    "\n",
    "https://towardsdatascience.com/introduction-to-linear-regression-in-python-c12a072bedf0\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}