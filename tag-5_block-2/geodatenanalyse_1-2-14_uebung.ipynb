{
 "cells": [
  {
   "source": [
    "# Geodatenanalyse 1\n",
    "\n",
    "## Tag 5 / Block 2 / Übung 14: Logistische Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Für dieses Beispiel zur logistischen Regression in Python werden wir einen Datensatz aus Gelman et al. (2020) \" Regression and Other Stories\"  (Kapitel 13.5) nehmen. Dieser enthält Daten zu einer Umfrage, inwieweit Menschen in Bangladesch bereit sind ihren Trinkwasserbrunnen zu wechseln (\"ja\", \"nein\"), sowie Angaben zur Arsenkonzentration (\"arsenic\"), zur Distanz zum nächsten (nicht Arsen-belasteten) Brunnen (\"dist\" und \"dist100\"), ob der Befragte Mitglied einer Gemeinde-Vereinigung o.ä. ist (\"assoc\"), und Angaben zum Bildungsniveau der Befragten (\"edu\" und \"edu4\"). \n",
    "\n",
    "Lest die entsprechenden Daten aus \"wells.csv\" in Euer Notebook ein.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "### Explorative Datenanalyse\n",
    "\n",
    "Für eine logistische Regression müssen wir zuerst sicherstellen, dass die abhängige Variable (Brunnen wechseln: ja = 1 / nein = 0) eine ausgeglichene Anzahl der Werte \"0\" und \"1\" hat (+/- 20% sind okay). Dies könnt Ihr z.B. graphisch machen, mit Hilfe von `seaborn.countplot()`.\n",
    "\n",
    "Gebt dafür als Inputs \"x=...\" die unabhängige Variable, und \"data=...\" den gesamten Datensatz an.    \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Speichert nun die unabhängige Variable separat als \"Series\", und die abhängigen Variablen \"arsenic\" und \"dist100\" in einem eigenen DataFrame ab. Plottet anschließend die beiden abhängigen Variablen als Histogramme und Scattplots (z.B. `seaborn.pairplot(X)`), um zu beurteilen ob Korrelationen zwischen den Parametern vorhanden sind. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Wie in der letzten Übung, teilt nun die beiden Datensätze in Trainingsdaten zur Modellierung und Testdaten zum späteren Evaluieren der Modellanpassung auf.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "### Logistische Regression mit `statsmodels`\n",
    "\n",
    "Als nächstes erstellen wir ein logistisches Modell mit Hilfe von `statsmodels.api` und der Funktion `Logit()`. Gebt dabei als Inputs die eben erzeugten entsprechenden Trainingsdaten an. Lasst Euch in einem zweiten Schritt dann die Ergebnisse des angepassten Modells mit der Funktion `.fit()` erzeugen. Über den Befehl \"print(Ergebnisse.summary())\" könnt Ihr Euch eine Zusammenfassung der Anpassung anzeigen lassen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Die Zusammenfassung zeigt übersichtlich nochmal alle Einstellungen und Kennwerte der Modellanpassung. Unter anderen könnt Ihr hier Koeffizienten der Regression, sowie die p-Werte der Parameter nachschauen und interpretieren. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Logistische Regression mit `scikit-learn`\n",
    "\n",
    "Als nächstes führen wir eine logistische Regression mit `scikit-learn` durch. Die Objekte darin haben mehr Funktionen in Bezug auf verschiedene Optimierungsalgorithmen, Evaluierungskriterien usw. \n",
    "\n",
    "Definiert Euch zuerst ein Regressionsobjekt über `sklearn.linear_model.LogisticRegression()`, unter der Angabe von \"C = 0.1\" um die Stärke der Regularisation anzupassen. Führt danach mit dem erzeugten Regressionsobjekt die Anpassung an die Trainingsdaten durch (`object.fit()`). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Mit dem gleichen Objekt könnt ihr nun mit `.predict()` Vorhersagen an den X-Werten des Testdatensatzen machen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Jetzt wollen wir die Modellanpassung evaluieren. Dazu werden wir uns einige Beispiele, wie den Jaccard-Index, die Wahrheitsmattrix und die Trefferquote ausgeben lassen. \n",
    "\n",
    "`sklearn.metrics` enthält die vordefinierten Funktionen `jaccard_score()` und `confusion_matrix()`. Wendet diese auf die entsprechenden Test- und Trainingsdaten an, und interpretiert die Werte. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Bestimmt nun basierend auf der Wahrheitsmatrix die Trefferquote des logistischen Regressionsmodells. Vergleicht das Ergebniss mit dem Wert des Jaccard-Index.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben"
   ]
  },
  {
   "source": [
    "Als letztes, stellt nun noch die Ergebnisse der logistischen Regression graphisch dar. Plottet dazu die Werte von abhängigen Variable als Scatterplot über die beiden betrachteten unabhängigen Variablen (\"arsenic\" und \"dist100\"). \n",
    "\n",
    "Für die Darstellung der angepassten logistischen Regressionskurve erzeugt Euch zuerst mit Hilfe von `numpy.linspace()` geeignete Werte für die jeweilige abhängige Variable. Um die entsprechenden unabhängigen Werte zu berechnen, könnt Ihr `scipy.special.expit()` benutzen. Damit können Werte für logistische Funktionen berechnet werden. \n",
    "\n",
    "Als Input benötigt diese Funktion den folgenden Ausdruck: `X * Regressionsobjekt.coef_ + Regressionsobjekt.intercept_`. Passt diesen Ausdruck in Bezug auf die Indizes entsprechend an, um Euch für beide Parameter Werte für die Darstellung der logistischen Funktion erzeugen zu lassen. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier Code eingeben\n"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "## Ende\n",
    "\n",
    "### Referenzen: \n",
    "\n",
    "Gelman et al. (2020) Regression and Other Stories, Cambridge University Press\n",
    "\n",
    "https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "\n",
    "https://medium.com/codex/machine-learning-logistic-regression-with-python-5ed4ded9d146\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}